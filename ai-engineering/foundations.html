<!DOCTYPE html>
<html lang="en-US">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>AI Engineering Foundations (Week 0-1) | Isayah Young Burke</title>
    <meta name="generator" content="VuePress 1.9.9">
    
    <link rel="icon" href="../favicon.ico">
    <meta name="description" content="AI Engineering foundations covering setup, transformers overview, and building your first sentiment analysis API.">
    <link rel="stylesheet" href="../assets/css/styles.css">
</head>
<body>
    <div id="app" class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="../index.html" class="home-link router-link-active"><span class="site-name">Isayah Young Burke</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="https://buttondown.email/zaylegend" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Subscribe
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div><div class="nav-item"><a href="https://twitter.com/zaylegend" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Twitter
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>Miscellaneous</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a class='sidebar-link' href='../chess.html'>Chess</a></li><li><a class='sidebar-link' href='../climbing.html'>Climbing</a></li><li><a class='sidebar-link' href='../consciousness.html'>Consciousness</a></li><li><a class='sidebar-link' href='../languages.html'>Languages</a></li><li><a class='sidebar-link' href='../mathematics.html'>Mathematics</a></li><li><a class='sidebar-link' href='../meditation.html'>Meditation</a></li><li><a class='sidebar-link' href='../mimetic-theory.html'>Mimetic Theory</a></li><li><a class='sidebar-link' href='../music.html'>Music</a></li><li><a class='sidebar-link' href='../physics.html'>Physics</a></li><li><a class='sidebar-link' href='../public-speaking.html'>Public Speaking</a></li><li><a class='sidebar-link' href='../pyrolysis.html'>Pyrolysis</a></li><li><a class='sidebar-link' href='../relationships.html'>Relationships</a></li><li><a class='sidebar-link' href='../soil.html'>Soil Health</a></li><li><a class='sidebar-link' href='../space.html'>Space</a></li><li><a class='sidebar-link' href='../trees.html'>Trees</a></li><li><a class='sidebar-link' href='../writing.html'>Writing</a></li><li><a class='sidebar-link' href='../zoology.html'>Zoology</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>Tech</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a class='sidebar-link' href='../tech/ai-development.html'>AI Development</a></li><li><a class='sidebar-link' href='../tech/development-workflows.html'>Development Workflows</a></li><li><a class='sidebar-link' href='../tech/session-recaps.html'>Session Recaps</a></li><li><a class='sidebar-link' href='../tech/automation-tools.html'>Automation Tools</a></li><li><a class='sidebar-link' href='../tech/awesome-list.html'>Awesome List</a></li><li><a class='sidebar-link' href='../tech/bash-profile.html'>MacOS Bash Profile</a></li><li><a class='sidebar-link' href='../tech/docker.html'>Docker Cheatsheet</a></li><li><a class='sidebar-link' href='../tech/html-cheatsheet.html'>HTML Cheatsheet</a></li><li><a class='sidebar-link' href='../tech/macos-tips.html'>MacOS tips</a></li><li><a class='sidebar-link' href='../tech/mental-models.html'>Mental Models</a></li><li><a class='sidebar-link' href='../tech/postgresql.html'>PostgreSQL cheatsheet</a></li><li><a class='sidebar-link' href='../tech/postgres-data.html'>Loading JSON into Postgres</a></li><li><a class='sidebar-link' href='../tech/regex.html'>Regex Cheatsheet</a></li><li><a class='sidebar-link' href='../tech/secrets-management-sops.html'>Secrets management - SOPS</a></li><li><a class='sidebar-link' href='../tech/seo.html'>SEO Cheatsheet</a></li><li><a class='sidebar-link' href='../tech/today-i-learned.html'>Today I Learned</a></li><li><a class='sidebar-link' href='../tech/vscode-snippets.html'>VSCode Snippets</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>Courses</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><section class="sidebar-group depth-1"><p class="sidebar-heading"><span>AI Engineering</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a class='sidebar-link' href='index.html'>Course Overview</a></li><li><a class='sidebar-link' href='syllabus.html'>Full Syllabus</a></li><li><a class='sidebar-link' href='foundations.html'>Foundations (Week 0-1)</a></li><li><a class='sidebar-link' href='core-applications.html'>Core Applications (Week 2-3)</a></li><li><a class='sidebar-link' href='advanced-techniques.html'>Advanced Techniques (Week 4-5)</a></li><li><a class='sidebar-link' href='capstone-advanced.html'>Capstone & Advanced (Week 6-7)</a></li></ul></section></li><li><a class='sidebar-link' href='../courses/mindfulness.html'>Mindfulness Course</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>Business</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a class='sidebar-link' href='../business/hiring.html'>Hiring</a></li><li><a class='sidebar-link' href='../business/management.html'>Management</a></li><li><a class='sidebar-link' href='../business/sales.html'>Sales</a></li><li><a class='sidebar-link' href='../business/marketing.html'>Marketing</a></li><li><a class='sidebar-link' href='../business/fundraising.html'>Fundraising</a></li><li><a class='sidebar-link' href='../business/resources.html'>Startup Resources</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>Levels</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a class='sidebar-link' href='../levels/business.html'>Business</a></li><li><a class='sidebar-link' href='../levels/life.html'>Life</a></li><li><a class='sidebar-link' href='../levels/leadership.html'>Leadership</a></li><li><a class='sidebar-link' href='../levels/learning.html'>Learning</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>Philosophy</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a class='sidebar-link' href='../philosophy/ethics.html'>Ethics</a></li><li><a class='sidebar-link' href='../philosophy/buddhism.html'>Buddhism</a></li><li><a class='sidebar-link' href='../philosophy/stoicism.html'>Stoicism</a></li><li><a class='sidebar-link' href='../philosophy/desire.html'>Desire</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>People</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a class='sidebar-link' href='../people.html'>People</a></li><li><a class='sidebar-link' href='../people/lee-kuan-yew.html'>Lee Kuan Yew</a></li><li><a class='sidebar-link' href='../people/jensen-huang.html'>Jensen Huang</a></li><li><a class='sidebar-link' href='../people/elon-musk.html'>Elon Musk</a></li><li><a class='sidebar-link' href='../people/marlon-brando.html'>Marlon Brando</a></li><li><a class='sidebar-link' href='../people/nelson-mandela.html'>Nelson Mandela</a></li></ul></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="ai-engineering-foundations-week-0-1"><a href="#ai-engineering-foundations-week-0-1" class="header-anchor">#</a> AI Engineering Foundations (Week 0-1)</h1> <h2 id="course-introduction-setup"><a href="#course-introduction-setup" class="header-anchor">#</a> Course Introduction &amp; Setup</h2> <h3 id="what-makes-this-course-different"><a href="#what-makes-this-course-different" class="header-anchor">#</a> What Makes This Course Different?</h3> <p>This course bridges the gap between "playing with AI models" and "building real AI applications that people actually use." You'll learn to think like a product engineer who specializes in AI, not just a data scientist who can train models.</p> <h4 id="project-based-learning"><a href="#project-based-learning" class="header-anchor">#</a> Project-Based Learning</h4> <p>Instead of abstract tutorials, you'll build 6+ complete applications:</p> <ul><li><strong>Week 1</strong>: LLM Playground (like ChatGPT's interface)</li> <li><strong>Week 2</strong>: Customer Support Chatbot (fine-tuned for your business)</li> <li><strong>Week 3</strong>: Web Research Agent (like Perplexity AI)</li> <li><strong>Week 4</strong>: Deep Research Assistant (multi-step reasoning)</li> <li><strong>Week 5</strong>: Voice-Enabled Image Generator (multimodal AI)</li> <li><strong>Week 6</strong>: Your Choice Capstone Project</li></ul> <h4 id="production-ready-tech-stack"><a href="#production-ready-tech-stack" class="header-anchor">#</a> Production-Ready Tech Stack</h4> <p>You'll use the same tools that power real AI companies:</p> <ul><li><strong>Hugging Face</strong>: The GitHub of AI models (100,000+ models)</li> <li><strong>IONOS</strong>: Enterprise cloud infrastructure for deployment</li> <li><strong>ElevenLabs</strong>: State-of-the-art voice AI</li> <li><strong>n8n</strong>: Workflow automation (connect AI to everything else)</li></ul> <h3 id="course-philosophy-build-to-learn"><a href="#course-philosophy-build-to-learn" class="header-anchor">#</a> Course Philosophy: Build to Learn</h3> <p><strong>Traditional Approach</strong>: Theory → Practice → Maybe Build Something<br> <strong>Our Approach</strong>: Build → Understand Why It Works → Build Better</p> <p>Each week follows this pattern:</p> <ol><li><strong>Quick Intro</strong>: Just enough theory to get started</li> <li><strong>Hands-On Building</strong>: Immediate project work</li> <li><strong>Deep Dive</strong>: Understand the "why" behind what you built</li> <li><strong>Enhancement</strong>: Add advanced features</li> <li><strong>Deployment</strong>: Make it available to real users</li></ol> <h3 id="success-metrics"><a href="#success-metrics" class="header-anchor">#</a> Success Metrics</h3> <p>By the end of this course, you should be able to:</p> <ul><li><strong>Technical Skills</strong>: Deploy any Hugging Face model as a production API</li> <li><strong>System Design</strong>: Architect multi-service AI applications</li> <li><strong>Problem Solving</strong>: Break down complex AI problems into solvable pieces</li> <li><strong>Portfolio</strong>: Have 6+ GitHub repos showcasing different AI capabilities</li> <li><strong>Career Readiness</strong>: Confidently discuss AI engineering in interviews</li></ul> <hr> <h2 id="week-0-foundation-project"><a href="#week-0-foundation-project" class="header-anchor">#</a> Week 0: Foundation Project</h2> <h3 id="deploy-distilbert-sentiment-api"><a href="#deploy-distilbert-sentiment-api" class="header-anchor">#</a> Deploy DistilBERT Sentiment API</h3> <p>Build and deploy your first production AI API using DistilBERT for sentiment analysis. This project teaches you the fundamentals of model deployment, API development, and cloud hosting.</p> <h4 id="what-you-ll-build"><a href="#what-you-ll-build" class="header-anchor">#</a> What You'll Build</h4> <ul><li><strong>FastAPI application</strong> with sentiment analysis endpoints</li> <li><strong>Docker configuration</strong> for containerized deployment</li> <li><strong>Web interface</strong> for interactive testing</li> <li><strong>Public deployment</strong> on IONOS cloud infrastructure</li></ul> <h4 id="key-technologies"><a href="#key-technologies" class="header-anchor">#</a> Key Technologies</h4> <ul><li><strong>DistilBERT</strong>: Lightweight BERT model for sentiment analysis</li> <li><strong>FastAPI</strong>: Modern Python web framework for APIs</li> <li><strong>Docker</strong>: Containerization for consistent deployment</li> <li><strong>Ubuntu 22.04</strong>: Production server environment</li></ul> <h4 id="api-endpoints"><a href="#api-endpoints" class="header-anchor">#</a> API Endpoints</h4> <ul><li><code>GET /</code>: Service information</li> <li><code>GET /health</code>: Health check endpoint</li> <li><code>POST /analyze</code>: Analyze single text sentiment</li> <li><code>POST /analyze-batch</code>: Analyze multiple texts</li> <li><code>GET /demo</code>: Web interface for testing</li></ul> <h4 id="example-response"><a href="#example-response" class="header-anchor">#</a> Example Response</h4> <div class="language-json extra-class"><pre class="language-json"><code><span class="token punctuation">{</span>
  <span class="token property">&quot;text&quot;</span><span class="token operator">:</span> <span class="token string">&quot;I love this AI course!&quot;</span><span class="token punctuation">,</span>
  <span class="token property">&quot;sentiment&quot;</span><span class="token operator">:</span> <span class="token string">&quot;POSITIVE&quot;</span><span class="token punctuation">,</span>
  <span class="token property">&quot;confidence&quot;</span><span class="token operator">:</span> <span class="token number">0.999</span><span class="token punctuation">,</span>
  <span class="token property">&quot;scores&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
    <span class="token property">&quot;POSITIVE&quot;</span><span class="token operator">:</span> <span class="token number">0.999</span><span class="token punctuation">,</span>
    <span class="token property">&quot;NEGATIVE&quot;</span><span class="token operator">:</span> <span class="token number">0.001</span>
  <span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token property">&quot;processing_time&quot;</span><span class="token operator">:</span> <span class="token number">0.045</span>
<span class="token punctuation">}</span>
</code></pre></div> <hr> <h2 id="week-1-llm-playground"><a href="#week-1-llm-playground" class="header-anchor">#</a> Week 1: LLM Playground</h2> <h3 id="understanding-transformer-architecture"><a href="#understanding-transformer-architecture" class="header-anchor">#</a> Understanding Transformer Architecture</h3> <p>Before building with LLMs, you need to understand how they work. Transformers revolutionized AI by allowing models to process all words simultaneously and learn relationships between any two words, regardless of distance.</p> <h4 id="the-transformer-revolution"><a href="#the-transformer-revolution" class="header-anchor">#</a> The Transformer Revolution</h4> <p><strong>Before Transformers</strong>: Sequential Processing</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># How old RNN/LSTM models processed text</span>
text <span class="token operator">=</span> <span class="token string">&quot;The cat sat on the mat&quot;</span>
hidden_state <span class="token operator">=</span> initial_state

<span class="token keyword">for</span> word <span class="token keyword">in</span> text<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    hidden_state <span class="token operator">=</span> process_word<span class="token punctuation">(</span>word<span class="token punctuation">,</span> hidden_state<span class="token punctuation">)</span>
    <span class="token comment"># Model can only &quot;remember&quot; through hidden_state</span>
    <span class="token comment"># Long sequences → vanishing gradients</span>
    <span class="token comment"># Can't process in parallel</span>
</code></pre></div> <p><strong>After Transformers</strong>: Parallel Attention</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># How transformers process text</span>
text <span class="token operator">=</span> <span class="token string">&quot;The cat sat on the mat&quot;</span>
tokens <span class="token operator">=</span> tokenize<span class="token punctuation">(</span>text<span class="token punctuation">)</span>  <span class="token comment"># All at once</span>
attention_weights <span class="token operator">=</span> compute_attention<span class="token punctuation">(</span>tokens<span class="token punctuation">)</span>  <span class="token comment"># All pairs simultaneously</span>
output <span class="token operator">=</span> apply_attention<span class="token punctuation">(</span>tokens<span class="token punctuation">,</span> attention_weights<span class="token punctuation">)</span>  <span class="token comment"># Parallel processing</span>
</code></pre></div> <h4 id="core-components"><a href="#core-components" class="header-anchor">#</a> Core Components</h4> <h5 id="_1-self-attention-mechanism"><a href="#_1-self-attention-mechanism" class="header-anchor">#</a> 1. Self-Attention Mechanism</h5> <p>The heart of transformers - allows each word to "attend" to every other word:</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># Simplified attention calculation</span>
<span class="token keyword">def</span> <span class="token function">attention</span><span class="token punctuation">(</span>query<span class="token punctuation">,</span> key<span class="token punctuation">,</span> value<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&quot;&quot;&quot;
    Query: What am I looking for?
    Key: What does each position contain?
    Value: What information should I extract?
    &quot;&quot;&quot;</span>
    scores <span class="token operator">=</span> query <span class="token operator">@</span> key<span class="token punctuation">.</span>T  <span class="token comment"># Dot product for similarity</span>
    weights <span class="token operator">=</span> softmax<span class="token punctuation">(</span>scores<span class="token punctuation">)</span>  <span class="token comment"># Convert to probabilities</span>
    output <span class="token operator">=</span> weights <span class="token operator">@</span> value  <span class="token comment"># Weighted sum of values</span>
    <span class="token keyword">return</span> output
</code></pre></div> <h5 id="_2-multi-head-attention"><a href="#_2-multi-head-attention" class="header-anchor">#</a> 2. Multi-Head Attention</h5> <p>Instead of one attention mechanism, use multiple "heads" to capture different types of relationships:</p> <ul><li><strong>Head 1</strong>: Subject-verb relationships</li> <li><strong>Head 2</strong>: Adjective-noun pairs</li> <li><strong>Head 3</strong>: Long-distance dependencies</li> <li><strong>Head 4</strong>: Syntactic structure</li></ul> <h4 id="three-transformer-architectures"><a href="#three-transformer-architectures" class="header-anchor">#</a> Three Transformer Architectures</h4> <h5 id="encoder-only-bert-style"><a href="#encoder-only-bert-style" class="header-anchor">#</a> Encoder-Only (BERT-style)</h5> <ul><li><strong>Purpose</strong>: Understanding and analyzing text</li> <li><strong>Use Cases</strong>: Classification, question answering, sentiment analysis</li> <li><strong>Popular Models</strong>: BERT, DistilBERT, RoBERTa, DeBERTa</li></ul> <h5 id="decoder-only-gpt-style"><a href="#decoder-only-gpt-style" class="header-anchor">#</a> Decoder-Only (GPT-style)</h5> <ul><li><strong>Purpose</strong>: Text generation and completion</li> <li><strong>Use Cases</strong>: Text generation, conversation, code completion</li> <li><strong>Popular Models</strong>: GPT-2, GPT-3, GPT-4, LLaMA, Falcon</li></ul> <h5 id="encoder-decoder-t5-style"><a href="#encoder-decoder-t5-style" class="header-anchor">#</a> Encoder-Decoder (T5-style)</h5> <ul><li><strong>Purpose</strong>: Text-to-text transformation</li> <li><strong>Use Cases</strong>: Translation, summarization, question answering</li> <li><strong>Popular Models</strong>: T5, BART, mT5, UL2</li></ul> <h3 id="interactive-llm-playground-project"><a href="#interactive-llm-playground-project" class="header-anchor">#</a> Interactive LLM Playground Project</h3> <p>Build a comprehensive interface for testing and comparing different language models with parameter controls and token visualization.</p> <h4 id="features"><a href="#features" class="header-anchor">#</a> Features</h4> <ul><li><strong>Model Selection</strong>: Switch between GPT-2, Falcon-7B, LLaMA-2</li> <li><strong>Parameter Controls</strong>: Adjust temperature, max tokens, top-p, top-k</li> <li><strong>Token Visualization</strong>: See how text gets tokenized</li> <li><strong>Probability Display</strong>: View token-by-token probabilities</li> <li><strong>Save/Share</strong>: Export interesting model outputs</li></ul> <h4 id="key-concepts"><a href="#key-concepts" class="header-anchor">#</a> Key Concepts</h4> <h5 id="tokenization"><a href="#tokenization" class="header-anchor">#</a> Tokenization</h5> <p>How models break text into processable units:</p> <ul><li><strong>BPE</strong>: Byte Pair Encoding</li> <li><strong>WordPiece</strong>: Google's tokenization method</li> <li><strong>SentencePiece</strong>: Language-agnostic tokenization</li></ul> <h5 id="generation-parameters"><a href="#generation-parameters" class="header-anchor">#</a> Generation Parameters</h5> <ul><li><strong>Temperature</strong>: Controls randomness (0.0 = deterministic, 1.0 = creative)</li> <li><strong>Top-p</strong>: Nucleus sampling - consider tokens that make up p% of probability mass</li> <li><strong>Top-k</strong>: Consider only the k most likely next tokens</li> <li><strong>Max Length</strong>: Maximum number of tokens to generate</li></ul> <h3 id="architecture-comparison-example"><a href="#architecture-comparison-example" class="header-anchor">#</a> Architecture Comparison Example</h3> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">from</span> transformers <span class="token keyword">import</span> pipeline

<span class="token comment"># Encoder model (BERT) - great for understanding</span>
classifier <span class="token operator">=</span> pipeline<span class="token punctuation">(</span><span class="token string">&quot;sentiment-analysis&quot;</span><span class="token punctuation">)</span>
result <span class="token operator">=</span> classifier<span class="token punctuation">(</span><span class="token string">&quot;I love transformers!&quot;</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">f&quot;Classification: <span class="token interpolation"><span class="token punctuation">{</span>result<span class="token punctuation">}</span></span>&quot;</span><span class="token punctuation">)</span>

<span class="token comment"># Decoder model (GPT-2) - great for generation</span>
generator <span class="token operator">=</span> pipeline<span class="token punctuation">(</span><span class="token string">&quot;text-generation&quot;</span><span class="token punctuation">,</span> model<span class="token operator">=</span><span class="token string">&quot;gpt2&quot;</span><span class="token punctuation">)</span>
result <span class="token operator">=</span> generator<span class="token punctuation">(</span><span class="token string">&quot;Transformers are revolutionary because&quot;</span><span class="token punctuation">,</span> max_length<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">f&quot;Generation: <span class="token interpolation"><span class="token punctuation">{</span>result<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'generated_text'</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span>&quot;</span><span class="token punctuation">)</span>

<span class="token comment"># Encoder-Decoder (T5) - great for transformation</span>
summarizer <span class="token operator">=</span> pipeline<span class="token punctuation">(</span><span class="token string">&quot;summarization&quot;</span><span class="token punctuation">,</span> model<span class="token operator">=</span><span class="token string">&quot;t5-small&quot;</span><span class="token punctuation">)</span>
long_text <span class="token operator">=</span> <span class="token triple-quoted-string string">&quot;&quot;&quot;
Transformers are a type of neural network architecture that has become 
the foundation of modern natural language processing. They use attention 
mechanisms to process sequences of data, allowing them to understand 
context and relationships between words much better than previous approaches.
&quot;&quot;&quot;</span>
result <span class="token operator">=</span> summarizer<span class="token punctuation">(</span>long_text<span class="token punctuation">,</span> max_length<span class="token operator">=</span><span class="token number">30</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">f&quot;Summary: <span class="token interpolation"><span class="token punctuation">{</span>result<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'summary_text'</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span>&quot;</span><span class="token punctuation">)</span>
</code></pre></div> <hr> <h2 id="key-learning-outcomes"><a href="#key-learning-outcomes" class="header-anchor">#</a> Key Learning Outcomes</h2> <p>After completing the foundations weeks, you will:</p> <ul><li><strong>Understand</strong> how transformer architectures work and why they're revolutionary</li> <li><strong>Deploy</strong> your first production AI API with proper error handling and monitoring</li> <li><strong>Compare</strong> different model architectures and choose the right one for specific tasks</li> <li><strong>Build</strong> interactive interfaces for testing and exploring AI models</li> <li><strong>Master</strong> the fundamentals of tokenization and text generation parameters</li></ul> <h2 id="next-steps"><a href="#next-steps" class="header-anchor">#</a> Next Steps</h2> <p>With the foundations in place, you're ready to move on to:</p> <ul><li><a href="core-applications.html">Core Applications (Week 2-3)</a> - Building chatbots and web research agents</li> <li><a href="advanced-techniques.html">Advanced Techniques (Week 4-5)</a> - Deep reasoning and multimodal AI</li> <li><a href="capstone-advanced.html">Capstone &amp; Advanced (Week 6-7)</a> - Your independent project</li></ul> <hr> <h2 id="resources"><a href="#resources" class="header-anchor">#</a> Resources</h2> <ul><li><a href="https://jalammar.github.io/illustrated-transformer/" target="_blank" rel="noopener noreferrer">The Illustrated Transformer<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> – Visual explanation with diagrams</li> <li><a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noopener noreferrer">Attention Is All You Need<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> – The original transformer paper</li> <li><a href="https://fastapi.tiangolo.com/" target="_blank" rel="noopener noreferrer">FastAPI Documentation<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> – Comprehensive API framework guide</li> <li><a href="https://huggingface.co/course/chapter1/1" target="_blank" rel="noopener noreferrer">Hugging Face Course<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> – Official introduction to NLP with Transformers</li></ul></div> <footer class="page-edit"><div class="edit-link"><a href="https://github.com/yetog/yetog/knowledge-base/edit/main/ai-engineering/foundations.md" target="_blank" rel="noopener noreferrer">Edit this page</a> <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></div> <div class="last-updated"><span class="prefix">Last Updated:</span> <span class="time">10/11/2025, 12:00:00 AM</span></div></footer> <!----> </main></div><div class="global-ui"></div></div>
      <script src="../assets/js/search.js" defer></script>
  </body>
</html>